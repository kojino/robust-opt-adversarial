{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/kojin/anaconda/envs/ml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import batch_indices\n",
    "from cleverhans.attacks import DeepFool\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 10\n",
    "batch_size = 128 \n",
    "drop_ratio = 0.10\n",
    "num_inputs = int(28 * 28 * (1-drop_ratio))\n",
    "noise_eps = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_model(input_ph,num_inputs, nb_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nb_classes,input_shape=(num_inputs,)))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF session and set as Keras backend session\n",
    "sess = tf.Session()\n",
    "# Get MNIST test data\n",
    "X_train, Y_train, X_test, Y_test = data_mnist()\n",
    "# Flatten image matrices\n",
    "num_train, num_rows, num_cols, num_channels = X_train.shape\n",
    "num_test, _, _, _ = X_test.shape\n",
    "X_train = X_train.reshape((num_train, num_rows * num_cols * num_channels))\n",
    "X_test = X_test.reshape((num_test, num_rows * num_cols * num_channels))\n",
    "# Randomly drop some ratio of pixels\n",
    "input_indices = np.random.choice(num_rows * num_cols, num_inputs, replace = False)\n",
    "X_train = X_train[:,input_indices]\n",
    "X_test = X_test[:,input_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, num_inputs))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "# Wrap log reg model for applying adversarial examples\n",
    "model = logistic_regression_model(x,num_inputs)\n",
    "wrap = KerasModelWrapper(model, 10) \n",
    "\n",
    "# Define the objective\n",
    "logits = wrap.get_logits(x)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits)\n",
    "\n",
    "# Define the update func\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_step = optimizer.minimize(loss)\n",
    "acc, acc_op = tf.metrics.accuracy(labels=tf.argmax(y, 1), \n",
    "                                  predictions=tf.argmax(logits,1))\n",
    "\n",
    "# Define adv attack\n",
    "deepfool = DeepFool(wrap, sess=sess)\n",
    "deepfool_params = {'eps': noise_eps,\n",
    "               'clip_min': 0.,\n",
    "               'clip_max': 1.}\n",
    "\n",
    "# Attack images\n",
    "adv_x = deepfool.generate(x, **deepfool_params)\n",
    "# Consider the attack to be constant\n",
    "adv_x = tf.stop_gradient(adv_x)\n",
    "\n",
    "# Evaluate predictions on adv attacks\n",
    "preds = model(adv_x)\n",
    "acc_adv, acc_op_adv = tf.metrics.accuracy(labels=tf.argmax(y, 1), \n",
    "                                  predictions=tf.argmax(preds,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Acc: 0.88877\n",
      "Epoch: 1, Train Acc: 0.89706\n",
      "Epoch: 2, Train Acc: 0.90278\n",
      "Epoch: 3, Train Acc: 0.90650\n",
      "Epoch: 4, Train Acc: 0.90930\n",
      "Epoch: 5, Train Acc: 0.91142\n",
      "Epoch: 6, Train Acc: 0.91310\n",
      "Epoch: 7, Train Acc: 0.91459\n",
      "Epoch: 8, Train Acc: 0.91579\n",
      "Epoch: 9, Train Acc: 0.91685\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "rng = np.random.RandomState() # for batch sampling\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Compute number of batches\n",
    "    num_batches = int(math.ceil(float(len(X_train)) / batch_size))\n",
    "    assert num_batches * batch_size >= len(X_train)\n",
    "\n",
    "    # Indices to shuffle training set\n",
    "    index_shuf = list(range(len(X_train)))\n",
    "    rng.shuffle(index_shuf)\n",
    "    for batch in range(num_batches):\n",
    "\n",
    "        # Compute batch start and end indices\n",
    "        start, end = batch_indices(\n",
    "            batch, len(X_train), batch_size)\n",
    "\n",
    "        # Perform one training step\n",
    "        feed_dict = {x: X_train[index_shuf[start:end]],\n",
    "                     y: Y_train[index_shuf[start:end]]}\n",
    "        sess.run(train_step,feed_dict=feed_dict)\n",
    "    \n",
    "    feed_dict = {x: X_train,\n",
    "                 y: Y_train}\n",
    "    acc_val = sess.run(acc_op,feed_dict=feed_dict)\n",
    "    print(f\"Epoch: {epoch}, Train Acc: {acc_val:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9169869"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "feed_dict = {x: X_test,\n",
    "             y: Y_test}\n",
    "sess.run(acc_op,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict = {x: X_test,\n",
    "             y: Y_test}\n",
    "sess.run(acc_op_adv,feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
